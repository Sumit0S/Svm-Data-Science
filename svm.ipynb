{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8dbbe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>12.57</td>\n",
       "      <td>138</td>\n",
       "      <td>108</td>\n",
       "      <td>17</td>\n",
       "      <td>203</td>\n",
       "      <td>128</td>\n",
       "      <td>Good</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>6.14</td>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>120</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>7.41</td>\n",
       "      <td>162</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>368</td>\n",
       "      <td>159</td>\n",
       "      <td>Medium</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>5.94</td>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>284</td>\n",
       "      <td>95</td>\n",
       "      <td>Bad</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9.71</td>\n",
       "      <td>134</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>120</td>\n",
       "      <td>Good</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0     9.50        138      73           11         276    120       Bad   42   \n",
       "1    11.22        111      48           16         260     83      Good   65   \n",
       "2    10.06        113      35           10         269     80    Medium   59   \n",
       "3     7.40        117     100            4         466     97    Medium   55   \n",
       "4     4.15        141      64            3         340    128       Bad   38   \n",
       "..     ...        ...     ...          ...         ...    ...       ...  ...   \n",
       "395  12.57        138     108           17         203    128      Good   33   \n",
       "396   6.14        139      23            3          37    120    Medium   55   \n",
       "397   7.41        162      26           12         368    159    Medium   40   \n",
       "398   5.94        100      79            7         284     95       Bad   50   \n",
       "399   9.71        134      37            0          27    120      Good   49   \n",
       "\n",
       "     Education Urban   US Unnamed: 11  \n",
       "0           17   Yes  Yes         NaN  \n",
       "1           10   Yes  Yes         NaN  \n",
       "2           12   Yes  Yes         NaN  \n",
       "3           14   Yes  Yes         NaN  \n",
       "4           13   Yes   No         NaN  \n",
       "..         ...   ...  ...         ...  \n",
       "395         14   Yes  Yes         NaN  \n",
       "396         11    No  Yes         NaN  \n",
       "397         18   Yes  Yes         NaN  \n",
       "398         12   Yes  Yes         NaN  \n",
       "399         16   Yes  Yes         NaN  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/Users/sumit/Downloads/Carseats.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d403bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Extract the images and labels\n",
    "images = digits.images\n",
    "labels = digits.target\n",
    "\n",
    "# Display the first 10 images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2ae5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (1797, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 29  1]\n",
      " [ 0  0  0  0  0  1  0  1  0 38]]\n",
      "\n",
      "Kernel: linear\n",
      "Accuracy: 0.9777777777777777\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       0.97      0.94      0.96        34\n",
      "           4       0.98      0.98      0.98        46\n",
      "           5       0.96      1.00      0.98        47\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.93      0.94        40\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "\n",
      "Kernel: poly\n",
      "Accuracy: 0.9916666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       1.00      0.98      0.99        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Kernel: rbf\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Kernel: sigmoid\n",
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        33\n",
      "           1       0.68      0.75      0.71        28\n",
      "           2       0.97      0.88      0.92        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.92      0.96      0.94        46\n",
      "           5       0.96      0.94      0.95        47\n",
      "           6       0.94      0.97      0.96        35\n",
      "           7       0.94      0.97      0.96        34\n",
      "           8       0.79      0.73      0.76        30\n",
      "           9       0.83      0.85      0.84        40\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.90      0.90       360\n",
      "\n",
      "\n",
      "Degree: 2\n",
      "Accuracy: 0.9888888888888889\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      1.00      0.99        47\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.93      0.97        30\n",
      "           9       0.95      0.97      0.96        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Degree: 3\n",
      "Accuracy: 0.9916666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       1.00      0.98      0.99        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Degree: 4\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Degree: 5\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Gamma: scale\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gamma: auto\n",
      "Accuracy: 0.4666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.60        33\n",
      "           1       1.00      0.71      0.83        28\n",
      "           2       1.00      0.48      0.65        33\n",
      "           3       0.15      1.00      0.26        34\n",
      "           4       1.00      0.28      0.44        46\n",
      "           5       1.00      0.06      0.12        47\n",
      "           6       1.00      0.74      0.85        35\n",
      "           7       1.00      0.56      0.72        34\n",
      "           8       1.00      0.47      0.64        30\n",
      "           9       1.00      0.23      0.37        40\n",
      "\n",
      "    accuracy                           0.47       360\n",
      "   macro avg       0.92      0.50      0.55       360\n",
      "weighted avg       0.92      0.47      0.52       360\n",
      "\n",
      "\n",
      "Gamma: 0.1\n",
      "Accuracy: 0.07777777777777778\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.08      1.00      0.14        28\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        35\n",
      "           7       0.00      0.00      0.00        34\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.08       360\n",
      "   macro avg       0.01      0.10      0.01       360\n",
      "weighted avg       0.01      0.08      0.01       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gamma: 1\n",
      "Accuracy: 0.07777777777777778\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.08      1.00      0.14        28\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        35\n",
      "           7       0.00      0.00      0.00        34\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.08       360\n",
      "   macro avg       0.01      0.10      0.01       360\n",
      "weighted avg       0.01      0.08      0.01       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gamma: 10\n",
      "Accuracy: 0.07777777777777778\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.08      1.00      0.14        28\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        35\n",
      "           7       0.00      0.00      0.00        34\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.08       360\n",
      "   macro avg       0.01      0.10      0.01       360\n",
      "weighted avg       0.01      0.08      0.01       360\n",
      "\n",
      "\n",
      "Random State: 0\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "Random State: 42\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sumit/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random State: 100\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "C: 0.1\n",
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.87      0.96      0.92        28\n",
      "           2       0.97      0.97      0.97        33\n",
      "           3       1.00      0.91      0.95        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.94      0.94      0.94        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.94      0.97      0.96        34\n",
      "           8       0.87      0.87      0.87        30\n",
      "           9       0.92      0.90      0.91        40\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "\n",
      "C: 1\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "C: 10\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.96      0.98      0.97        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "C: 100\n",
      "Accuracy: 0.9861111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.96      0.98      0.97        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Step 2: Check the shape of data\n",
    "print(\"Shape of data:\", digits.data.shape)\n",
    "\n",
    "# Step 3: Display the first 10 images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {digits.target[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Extract Independent and Dependent Variable\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Build an SVM model using Sklearn with default parameters\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Predict the target values in the testing set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Step 8: Apply classification metrics and visualize the results as graphs\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 9: Playing with SVM parameters\n",
    "# a) Kernel\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    svm_model = SVC(kernel=kernel)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nKernel: {kernel}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# b) Degree\n",
    "degrees = [2, 3, 4, 5]\n",
    "for degree in degrees:\n",
    "    svm_model = SVC(kernel='poly', degree=degree)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nDegree: {degree}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# c) Gamma\n",
    "gammas = ['scale', 'auto', 0.1, 1, 10]\n",
    "for gamma in gammas:\n",
    "    svm_model = SVC(kernel='rbf', gamma=gamma)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nGamma: {gamma}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# d) Random State\n",
    "random_states = [0, 42, 100]\n",
    "for random_state in random_states:\n",
    "    svm_model = SVC(random_state=random_state)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nRandom State: {random_state}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# e) C\n",
    "Cs = [0.1, 1, 10, 100]\n",
    "for C in Cs:\n",
    "    svm_model = SVC(C=C)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nC: {C}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1950a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
